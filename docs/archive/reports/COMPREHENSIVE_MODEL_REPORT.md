# üß† Zoe Model Benchmark Report - Pi 5 16GB + SSD

**Generated:** 2025-01-04 01:15:00  
**Hardware:** Raspberry Pi 5 16GB RAM + SSD  
**Test Environment:** Docker Ollama + Zoe MCP Server  

## üèÜ Executive Summary

After comprehensive testing of Claude's recommended models for Pi 5 16GB + SSD, here are the key findings:

### **ü•á Overall Winner: gemma3:1b**
- **Speed**: 6.25s average (fastest)
- **Reliability**: 100% success rate
- **Tool Calling**: 50% success (partial format issue)
- **Quality**: 6.2/10
- **Best For**: Quick queries, casual chat, fast responses

### **ü•à Balanced Champion: llama3.2:1b**
- **Speed**: 7.98s average
- **Reliability**: 100% success rate
- **Warmth**: 6.2/10 (warmest of reliable models)
- **Conciseness**: 8.0/10 (most concise)
- **Best For**: General conversation, balanced performance

### **ü•â Quality Leader: mistral:7b**
- **Quality**: 7.0/10 (highest)
- **Warmth**: 7.0/10 (warmest)
- **Tool Calling**: 100% (when working)
- **Reliability**: 25% (major issue)
- **Best For**: Complex reasoning (when it works)

## üìä Detailed Model Analysis

### Fast Lane Models (1-3 seconds target)

#### ‚úÖ **gemma3:1b** - RECOMMENDED
- **Performance**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
- **Speed**: 6.25s avg (excellent)
- **Success Rate**: 100%
- **Tool Calling**: 50% (format issue)
- **Quality**: 6.2/10
- **Warmth**: 5.2/10
- **Conciseness**: 7.5/10
- **Verdict**: ‚≠ê **BEST FAST MODEL** - Reliable, fast, good quality

#### ‚úÖ **qwen2.5:1.5b** - GOOD ALTERNATIVE
- **Performance**: ‚≠ê‚≠ê‚≠ê‚≠ê
- **Speed**: 10.51s avg (good)
- **Success Rate**: 100%
- **Tool Calling**: 50% (format issue)
- **Quality**: 5.0/10
- **Warmth**: 5.5/10
- **Conciseness**: 6.5/10
- **Verdict**: ‚≠ê **SOLID BACKUP** - Reliable but slower than gemma3:1b

#### ‚úÖ **llama3.2:1b** - CURRENT BENCHMARK WINNER
- **Performance**: ‚≠ê‚≠ê‚≠ê‚≠ê
- **Speed**: 7.98s avg (good)
- **Success Rate**: 100%
- **Tool Calling**: 50% (format issue)
- **Quality**: 5.8/10
- **Warmth**: 6.2/10 (warmest)
- **Conciseness**: 8.0/10 (most concise)
- **Verdict**: ‚≠ê **BEST BALANCE** - Warmest and most concise

### Balanced Models (3-10 seconds target)

#### ‚è≥ **qwen2.5:7b** - DOWNLOADING
- **Status**: Still downloading
- **Expected**: Primary workhorse ‚≠ê
- **Target**: 3-10 seconds
- **Verdict**: ‚è≥ **PENDING TEST**

#### ‚è≥ **qwen3:8b** - DOWNLOADING
- **Status**: Still downloading
- **Expected**: New flagship model
- **Target**: 3-10 seconds
- **Verdict**: ‚è≥ **PENDING TEST**

#### ‚è≥ **gemma3:4b** - DOWNLOADING
- **Status**: Still downloading
- **Expected**: Good balance
- **Target**: 3-10 seconds
- **Verdict**: ‚è≥ **PENDING TEST**

### Heavy Reasoning Models (10-30 seconds target)

#### ‚ö†Ô∏è **mistral:7b** - UNRELIABLE
- **Performance**: ‚≠ê‚≠ê‚≠ê
- **Speed**: 25.57s avg (slow)
- **Success Rate**: 25% (major reliability issue)
- **Tool Calling**: 100% (when working)
- **Quality**: 7.0/10 (highest)
- **Warmth**: 7.0/10 (warmest)
- **Conciseness**: 8.0/10
- **Verdict**: ‚ùå **TOO UNRELIABLE** - Great quality but fails too often

#### ‚è≥ **deepseek-r1:14b** - DOWNLOADING
- **Status**: Still downloading
- **Expected**: Complex analysis
- **Target**: 10-30 seconds
- **Verdict**: ‚è≥ **PENDING TEST**

#### ‚ùå **phi-4:14b** - FAILED TO DOWNLOAD
- **Status**: Download failed
- **Error**: "file does not exist"
- **Verdict**: ‚ùå **NOT AVAILABLE**

## üîß Critical Issues Identified

### 1. **Tool Calling Format Problem** üö®
**Issue**: All models generate partial tool calls instead of proper JSON format
- **Expected**: `[TOOL_CALL:add_to_list:{"list_name":"shopping","task_text":"bread","priority":"medium"}]`
- **Actual**: `[TOOL_CALL:add_to_list:bread:1]` or `[TOOL_CALL:control_home_assistant_device:living_room_light:{"on":true}]`

**Impact**: 50% tool calling success rate across all models
**Priority**: HIGH - Needs immediate fix

### 2. **Model Reliability Issues** ‚ö†Ô∏è
**Issue**: mistral:7b has 75% failure rate
**Impact**: Unusable for production
**Priority**: MEDIUM - Consider alternatives

### 3. **Download Failures** ‚ùå
**Issue**: phi-4:14b failed to download
**Impact**: Missing one of Claude's recommended models
**Priority**: LOW - Alternative models available

## üéØ Recommendations

### **Immediate Actions**

1. **Fix Tool Calling Format**
   - Update system prompts to be more explicit about JSON format
   - Add examples with proper JSON structure
   - Test with corrected prompts

2. **Set Default Model**
   - **Primary**: gemma3:1b (fastest, most reliable)
   - **Fallback**: llama3.2:1b (warmest, most concise)
   - **Avoid**: mistral:7b (too unreliable)

3. **Complete Model Downloads**
   - Wait for qwen2.5:7b, qwen3:8b, gemma3:4b, deepseek-r1:14b
   - Retry phi-4:14b download
   - Run full benchmark once complete

### **Model Selection Strategy**

#### **For Different Use Cases:**

- **Quick Actions**: gemma3:1b (6.25s avg)
- **Casual Chat**: llama3.2:1b (warmest, most concise)
- **Complex Reasoning**: Wait for balanced models to download
- **Production Use**: gemma3:1b (most reliable)

#### **Fallback Chain:**
1. gemma3:1b (primary)
2. llama3.2:1b (fallback)
3. qwen2.5:1.5b (backup)

## üìà Performance Metrics

### **Speed Rankings** (Fastest to Slowest)
1. gemma3:1b - 6.25s ‚ö°
2. llama3.2:1b - 7.98s ‚ö°
3. qwen2.5:1.5b - 10.51s üêå
4. mistral:7b - 25.57s üêåüêå

### **Quality Rankings** (Highest to Lowest)
1. mistral:7b - 7.0/10 üèÜ
2. gemma3:1b - 6.2/10 ‚≠ê
3. llama3.2:1b - 5.8/10 ‚≠ê
4. qwen2.5:1.5b - 5.0/10 ‚≠ê

### **Reliability Rankings** (Most to Least Reliable)
1. gemma3:1b - 100% ‚úÖ
2. llama3.2:1b - 100% ‚úÖ
3. qwen2.5:1.5b - 100% ‚úÖ
4. mistral:7b - 25% ‚ùå

## üö´ Models That Didn't Make the Cut

### **mistral:7b** - UNRELIABLE
- **Reason**: 75% failure rate
- **Issue**: Timeout errors, inconsistent responses
- **Verdict**: ‚ùå **REJECTED** - Too unreliable for production

### **phi-4:14b** - UNAVAILABLE
- **Reason**: Download failed
- **Issue**: "file does not exist" error
- **Verdict**: ‚ùå **UNAVAILABLE** - Cannot test

## üîÑ Next Steps

1. **Fix Tool Calling Format** (Priority: HIGH)
2. **Wait for Remaining Downloads** (Priority: MEDIUM)
3. **Run Full Benchmark** (Priority: MEDIUM)
4. **Optimize System Prompts** (Priority: LOW)
5. **Configure Model Routing** (Priority: LOW)

## üìä System Architecture Status

### ‚úÖ **Completed**
- Flexible model configuration system
- MCP server with all tools
- Model performance tracking
- Fallback chain implementation
- Comprehensive testing framework

### ‚è≥ **In Progress**
- Model downloads (4 models remaining)
- Tool calling format fixes
- Full benchmark completion

### üìã **Pending**
- RouteLLM optimization
- LiteLLM integration
- Mem Agent tuning
- LightRAG setup

---

**Report Status**: Partial (4/9 models tested)  
**Next Update**: When remaining models finish downloading  
**Confidence Level**: High for tested models, Medium for overall system

