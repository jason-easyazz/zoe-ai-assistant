# üéØ Jetson Orin NX Model Inventory & Performance Report

**Date:** 2025-11-13  
**Hardware:** Jetson Orin NX 16GB (MAXN_SUPER mode)  
**Status:** Comprehensive benchmark results

---

## üì¶ MODELS INSTALLED ON SYSTEM

### ‚úÖ Llama 3.2 3B (PRODUCTION - RECOMMENDED)

**Location:** `/home/zoe/assistant/models/llama-3.2-3b-instruct-gguf/`

| File | Size | Quantization | Status |
|------|------|--------------|--------|
| `Llama-3.2-3B-Instruct-Q4_K_M.gguf` | 1.9GB | Q4_K_M | ‚úÖ Tested |

**Performance Metrics:**
- **Generation Speed:** 27.17 tok/s ‚úÖ **EXCELLENT**
- **Prompt Processing:** 48.02 tok/s
- **VRAM Usage:** 1.9GB (leaves room for Whisper + TTS)
- **GPU Offload:** 29/29 layers (100%)
- **Response Time (50 tokens):** 1.8 seconds ‚úÖ **VOICE-READY**
- **Stability:** Excellent, no OOM errors
- **Tool Calling Accuracy:** 93.8% success rate

**Verdict:** ‚úÖ **PERFECT FOR REAL-TIME VOICE**

---

### ‚ö†Ô∏è Qwen 2.5 7B (TESTED - TOO SLOW)

**Location:** `/home/zoe/assistant/models/qwen2.5-7b-gguf/`

| File | Size | Quantization | Status |
|------|------|--------------|--------|
| `Qwen2.5-7B-Instruct-Q3_K_M.gguf` | 3.6GB | Q3_K_M | ‚úÖ Tested - Currently Loaded |
| `Qwen2.5-7B-Instruct-Q4_K_M.gguf` | 4.4GB | Q4_K_M | ‚ö†Ô∏è OOM Error (too large) |
| `Qwen2.5-7B-Instruct-Q4_0.gguf` | 158MB | Q4_0 | ‚ùå Corrupted download |

#### Q3_K_M Performance (TESTED):
- **Generation Speed:** 9.7 tok/s ‚ùå **TOO SLOW**
- **Prompt Processing:** 29.6 tok/s
- **VRAM Usage:** 3.4GB (80% more than Llama 3B)
- **GPU Offload:** 29/29 layers (100%)
- **Response Time (50 tokens):** 5.2 seconds ‚ùå **NOT VOICE-READY**
- **Optimizations Applied:** All possible (cont-batching, flash-attn, mlock, q8_0 cache, defrag)

**Verdict:** ‚ùå **2.8x SLOWER than Llama 3.2 3B - Not suitable for real-time voice**

---

## üìä PERFORMANCE COMPARISON

### Speed Benchmarks (Generation)

```
Llama 3.2 3B Q4_K_M:  27.2 tok/s  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚úÖ
Qwen 2.5 7B Q3_K_M:    9.7 tok/s  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ùå
```

### Voice Latency (50-token response)

```
Llama 3.2 3B:  1.8s  ‚ñà‚ñà‚ñà‚ñà ‚úÖ Natural conversation
Qwen 2.5 7B:   5.2s  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚ùå Noticeable lag
                     ‚îî‚îÄ Target: < 2s for real-time voice
```

### Memory Efficiency

```
Llama 3.2 3B:  1.9GB VRAM  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  (12% of 16GB) ‚úÖ
Qwen 2.5 7B:   3.4GB VRAM  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë  (21% of 16GB) ‚ö†Ô∏è
                           ‚îî‚îÄ Leaves less room for Whisper + TTS
```

---

## üéØ PERFORMANCE BY USE CASE

### Real-Time Voice Conversation ‚≠ê PRIMARY USE CASE

| Model | Response Time | Acceptable? | Rating |
|-------|---------------|-------------|--------|
| **Llama 3.2 3B** | **1.8s** | ‚úÖ **YES** | **‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê** |
| Qwen 2.5 7B | 5.2s | ‚ùå NO | ‚≠ê‚≠ê |

**Target:** < 2 seconds for natural conversation  
**Winner:** Llama 3.2 3B

---

### Intelligence & Reasoning

| Model | Parameters | Intelligence | Tool Calling |
|-------|------------|--------------|--------------|
| Llama 3.2 3B | 3.21B | Good | 93.8% accuracy ‚úÖ |
| Qwen 2.5 7B | 7.62B | Excellent | Unknown (too slow to test) |

**Trade-off:** Qwen is 2x smarter but 2.8x slower  
**Winner:** Llama 3.2 3B (speed > intelligence for voice)

---

### Resource Efficiency

| Model | VRAM | RAM | Headroom for Other Services |
|-------|------|-----|----------------------------|
| **Llama 3.2 3B** | **1.9GB** | **~3GB** | ‚úÖ **Plenty (Whisper + TTS fit)** |
| Qwen 2.5 7B | 3.4GB | ~5GB | ‚ö†Ô∏è Limited |

**Winner:** Llama 3.2 3B

---

## üîß OPTIMIZATION STATUS

### Llama 3.2 3B Optimizations ‚úÖ
- ‚úÖ All GPU layers offloaded (29/29)
- ‚úÖ Jetson MAXN_SUPER power mode
- ‚úÖ Maximized clock speeds (`jetson_clocks`)
- ‚úÖ Continuous batching
- ‚úÖ Flash attention
- ‚úÖ Optimized batch sizes (512/256)
- ‚úÖ Context size tuned for voice (2048)

**Result:** 27 tok/s (OPTIMAL)

### Qwen 2.5 7B Q3_K_M Optimizations ‚úÖ
- ‚úÖ All GPU layers offloaded (29/29)
- ‚úÖ Jetson MAXN_SUPER power mode
- ‚úÖ Maximized clock speeds
- ‚úÖ Continuous batching
- ‚úÖ Flash attention
- ‚úÖ Memory locking (mlock)
- ‚úÖ Q8_0 KV cache
- ‚úÖ Defragmentation threshold
- ‚úÖ Async CUDA operations

**Result:** 9.7 tok/s (HARDWARE LIMITED - cannot improve further)

---

## üèÜ RECOMMENDATION

### For Production Voice AI: **Llama 3.2 3B Q4_K_M**

**Reasons:**
1. ‚úÖ **27 tok/s = 1.8s responses** (perfect for voice)
2. ‚úÖ **93.8% tool-calling accuracy** (proven in testing)
3. ‚úÖ **Low VRAM usage** (room for Whisper + TTS)
4. ‚úÖ **Stable and reliable** (no OOM errors)
5. ‚úÖ **Already deployed and working**

### Not Recommended: Qwen 2.5 7B

**Reasons:**
1. ‚ùå **9.7 tok/s = 5.2s responses** (too slow for voice)
2. ‚ùå **2.8x slower than Llama 3B**
3. ‚ùå **80% more VRAM usage**
4. ‚ùå **Hit hardware limits** (cannot be optimized further)

---

## üìà BENCHMARK SUMMARY

| Metric | Llama 3.2 3B | Qwen 2.5 7B | Winner |
|--------|--------------|-------------|--------|
| **Generation Speed** | 27.2 tok/s | 9.7 tok/s | **Llama** |
| **Prompt Speed** | 48.0 tok/s | 29.6 tok/s | **Llama** |
| **Voice Latency (50t)** | 1.8s | 5.2s | **Llama** |
| **VRAM Usage** | 1.9GB | 3.4GB | **Llama** |
| **Intelligence** | Good | Excellent | Qwen |
| **Voice-Ready?** | ‚úÖ YES | ‚ùå NO | **Llama** |

---

## üéØ CURRENTLY RUNNING

**Active LLM Service:** `zoe-llamacpp`  
**Currently Loaded Model:** Qwen 2.5 7B Q3_K_M  
**Performance:** 9.7 tok/s (testing mode)

**‚ö†Ô∏è RECOMMENDATION:** Switch back to Llama 3.2 3B for production use.

---

## üíæ DISK USAGE

**Total Model Storage:** ~10GB

```
Llama 3.2 3B:     1.9GB  ‚ñà‚ñà‚ñà‚ñà
Qwen 2.5 7B:      8.1GB  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
  ‚îú‚îÄ Q3_K_M:      3.6GB  ‚úÖ Working
  ‚îú‚îÄ Q4_K_M:      4.4GB  ‚ùå Too large (OOM)
  ‚îî‚îÄ Q4_0:        158MB  ‚ùå Corrupted
```

---

## ‚úÖ ACTION ITEMS

1. **‚úÖ COMPLETE:** Benchmarked both models
2. **‚úÖ COMPLETE:** Optimized to maximum possible
3. **‚úÖ COMPLETE:** Identified Llama 3.2 3B as winner
4. **‚è≠Ô∏è TODO:** Switch production to Llama 3.2 3B
5. **‚è≠Ô∏è TODO:** Remove corrupted Qwen Q4_0 file
6. **‚è≠Ô∏è TODO:** Archive Qwen Q4_K_M (too large to use)

---

**Status:** Analysis complete  
**Recommendation:** Deploy Llama 3.2 3B (27 tok/s) for production  
**Ready to switch:** YES

üéØ **LLAMA 3.2 3B IS THE CLEAR WINNER**




