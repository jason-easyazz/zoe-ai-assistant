# Unified Memory Architecture - Implementation Status
**Date:** 2025-11-13  
**Status:** ğŸŸ¡ PARTIALLY COMPLETE

---

## âœ… Completed Tasks

### 1. Schema Migration (âœ… DONE)
- Added `is_self` column to `people` table
- Added `facts`, `preferences`, `personality_traits`, `interests` JSON columns
- Created composite index on `(user_id, is_self)` for fast self-entry lookups
- Schema now supports unified storage for all person data

### 2. Self Entries Created (âœ… DONE)
- Migrated 4 existing users to unified system:
  - `jason` (ID: 26)
  - `72038d8e-a3bb-4e41-9d9b-163b5736d2ce` (ID: 23)
  - `default` (ID: 24)
  - `service` (ID: 25)
- Each has `is_self=1` and `relationship="self"`

### 3. API Endpoints (âœ… DONE)
- `GET /api/people/self` - Get authenticated user's self entry
- `PATCH /api/people/self` - Update self entry with facts/preferences
- `POST /api/people` - Create person (supports `is_self` parameter)
- All endpoints respect user isolation

### 4. MCP Tools (âœ… DONE)
- `store_self_fact(fact_key, fact_value)` - Store personal facts
- `get_self_info(fact_key?)` - Retrieve personal facts
- Both tools implemented in `zoe-mcp-server/main.py`
- Tools successfully restart and load

---

## ğŸŸ¡ In Progress / Issues

### 5. Tool Discovery & Usage (âŒ NOT WORKING)
**Problem:** LLM is not selecting the new `store_self_fact` tool

**Test Result:**
```bash
User: "My favorite food is pizza"
Expected: store_self_fact(fact_key="favorite_food", fact_value="pizza")
Actual: search_memories(query="pizza")
```

**Root Cause Analysis:**
1. âœ… Schema: Ready
2. âœ… Self entries: Created
3. âœ… MCP tools: Implemented and running
4. âŒ **Tool discovery:** LLM doesn't know about new tools
5. âŒ **Model prompting:** No system prompt mentioning self-storage

**Why This Happens:**
- The chat router uses RouteLLM + model selection
- The LLM generates tool calls based on its training
- Without explicit prompting about the unified system, it defaults to old patterns
- `search_memories` is a familiar pattern from training

---

## ğŸ“‹ What Still Needs to Be Done

### Option A: Update System Prompt (RECOMMENDED)
Add explicit instructions to the LLM about the unified people table:

```python
SYSTEM_PROMPT = """
You are Zoe, a helpful AI assistant.

IMPORTANT: Personal fact storage rules:
- When user says "My favorite X is Y" â†’ use store_self_fact(fact_key="favorite_X", fact_value="Y")
- When user asks "What is my favorite X?" â†’ use get_self_info(fact_key="favorite_X")
- When user says "Sarah likes X" â†’ use add_person_attribute(person="Sarah", attribute="likes", value="X")

All person data (including self) is stored in a unified people table.
"""
```

### Option B: Enhanced Action Patterns
Update action patterns to explicitly trigger tool calling for personal facts:

```python
personal_fact_patterns = [
    "my favorite", "i like", "i love", "i prefer", "i work as",
    "i am a", "my birthday is", "my phone is", "i live in"
]
```

### Option C: Fine-tune Model
- Collect training data: "My X is Y" â†’ store_self_fact
- Fine-tune Qwen2.5-Coder or Llama model
- Deploy fine-tuned model

---

## ğŸ§ª Test Plan

### Test Suite: Natural Language Understanding

**Category: Personal Facts (Self)**
1. "My favorite food is pizza" â†’ `store_self_fact(favorite_food, pizza)`
2. "I love rock music" â†’ `store_self_fact(music_preference, rock)`
3. "My birthday is March 15th" â†’ `store_self_fact(birthday, March 15th)`
4. "What is my favorite food?" â†’ `get_self_info(favorite_food)`
5. "What do I like?" â†’ `get_self_info()`

**Category: Personal Facts (Others)**
6. "Sarah likes sushi" â†’ `add_person_attribute(Sarah, likes, sushi)`
7. "John's birthday is May 3rd" â†’ `add_person_attribute(John, birthday, May 3rd)`
8. "What does Sarah like?" â†’ `get_person_by_name(Sarah)` + read attributes

**Expected Success Rate:** 95-100% (30-32/32)

---

## ğŸ”§ Quick Fix Implementation

To get this working NOW, we can:

1. **Create auto-migration on chat** - When a new user sends their first message, automatically create self entry
2. **Update chat router** - Add explicit routing for "my X is Y" patterns
3. **Test with direct API calls** - Bypass LLM and test MCP tools directly

---

## ğŸ“Š Current Architecture

```
User: "My favorite food is pizza"
    â†“
Chat Router (/api/chat)
    â†“
RouteLLM â†’ Qwen2.5-Coder-7B (action model)
    â†“
LLM generates: <tool_call>store_self_fact(...)</tool_call>
    â†“
MCP Server executes tool
    â†“
Updates people table (user_id='jason', is_self=1)
    â†“
Response: "âœ… Stored: favorite_food = pizza"
```

**Current State:** Steps 1-3 work, step 4 fails (LLM selects wrong tool)

---

## ğŸ¯ Next Steps (Priority Order)

1. **HIGH:** Add system prompt with tool usage examples
2. **HIGH:** Test if llama.cpp model sees new MCP tools in tool list
3. **MEDIUM:** Add auto-creation of self entries on first chat
4. **MEDIUM:** Enhanced logging to debug tool selection
5. **LOW:** Fine-tune model with personal fact examples

---

## ğŸ’¾ Database State

```sql
-- Self entries: 4 users
SELECT COUNT(*) FROM people WHERE is_self=1;
-- Result: 4

-- Test data
SELECT user_id, name, facts FROM people WHERE is_self=1 LIMIT 3;
-- jason: {}
-- default: {}
-- service: {}

-- Conclusion: Schema ready, data ready, awaiting first successful store operation
```

---

## ğŸ“ Notes

- `user_profiles` table is now deprecated but kept for backward compatibility
- All new personal data should go into `people.facts` JSON field
- Migration was zero-downtime and zero-data-loss
- Can rollback by simply ignoring `is_self` column

---

## Status: BLOCKED ON

**Issue:** LLM tool selection not using new `store_self_fact` tool

**Blockers:**
1. Need to verify MCP tool list is passed to LLM
2. Need to add system prompt with tool usage examples
3. May need to adjust model temperature/top_p for better tool selection

**User Decision Required:** 
- Should we proceed with system prompt updates?
- Or should we test with direct MCP tool calls first to validate the implementation?





