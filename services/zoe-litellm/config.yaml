model_list:
  # Ultra-fast responses (Tier 1) - Claude's recommendations
  - model_name: gemma3-ultra-fast
    litellm_params:
      model: ollama/gemma3:1b
      api_base: http://zoe-ollama:11434
      temperature: 0.7
      top_p: 0.9
      max_tokens: 128
      timeout: 30
  - model_name: llama3.2-fast
    litellm_params:
      model: ollama/llama3.2:1b
      api_base: http://zoe-ollama:11434
  - model_name: qwen2.5-fast
    litellm_params:
      model: ollama/qwen2.5:1.5b
      api_base: http://zoe-ollama:11434
  
  # Balanced performance (Tier 2) - Sweet spot models
  - model_name: qwen2.5-balanced
    litellm_params:
      model: ollama/qwen2.5:3b
      api_base: http://zoe-ollama:11434
  - model_name: llama3.2-balanced
    litellm_params:
      model: ollama/llama3.2:3b
      api_base: http://zoe-ollama:11434
  - model_name: phi3-mini
    litellm_params:
      model: ollama/phi3:mini
      api_base: http://zoe-ollama:11434
  
  # High-quality models (Tier 3) - Recommended workhorses
  - model_name: qwen2.5-workhorse
    litellm_params:
      model: ollama/qwen2.5:7b
      api_base: http://zoe-ollama:11434
  - model_name: qwen3-flagship
    litellm_params:
      model: ollama/qwen3:8b
      api_base: http://zoe-ollama:11434
  - model_name: mistral-quality
    litellm_params:
      model: ollama/mistral:7b
      api_base: http://zoe-ollama:11434
  
  # Advanced reasoning (Tier 4) - Complex tasks
  - model_name: deepseek-r1-advanced
    litellm_params:
      model: ollama/deepseek-r1:14b
      api_base: http://zoe-ollama:11434
  
  # Code generation specialist
  - model_name: codellama-specialist
    litellm_params:
      model: ollama/codellama:7b
      api_base: http://zoe-ollama:11434
  # Cloud models for heavy tasks
  - model_name: gpt-3.5
    litellm_params:
      model: gpt-3.5-turbo
      api_key: os.environ/OPENAI_API_KEY
  - model_name: claude-instant
    litellm_params:
      model: claude-3-haiku-20240307
      api_key: os.environ/ANTHROPIC_API_KEY
  - model_name: claude-sonnet
    litellm_params:
      model: claude-3-sonnet-20240229
      api_key: os.environ/ANTHROPIC_API_KEY

router_settings:
  routing_strategy: "usage-based-routing-v2"
  num_retries: 3
  timeout: 60
  # Pre-load models for faster response - Claude's optimal setup
  prewarm: true
  prewarm_models: ["gemma3-ultra-fast", "qwen2.5-workhorse"]
  
  # Intelligent routing based on query type
  routing_rules:
    - condition: "query_type == 'quick'"
      target_model: "gemma3-ultra-fast"
    - condition: "query_type == 'conversation'"
      target_model: "qwen2.5-workhorse"
    - condition: "query_type == 'reasoning'"
      target_model: "deepseek-r1-advanced"
    - condition: "query_type == 'coding'"
      target_model: "codellama-specialist"
    - condition: "query_type == 'complex'"
      target_model: "qwen3-flagship"

general_settings:
  master_key: "sk-f3320300bb32df8f176495bb888ba7c8f87a0d01c2371b50f767b9ead154175f"
  disable_database_usage: true
  disable_spend_logs: true
  disable_otel_logging: true
  disable_ui: true
  database_url: "sqlite:///litellm.db"
  store_model_in_db: false
