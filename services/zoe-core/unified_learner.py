"""
Unified Learning Engine (Phase 6B)
Learn from ALL archived data across multiple data types simultaneously
"""

import logging
import json
from typing import List, Dict, Any, Optional
from pathlib import Path
from datetime import datetime, timedelta

from memvid.retriever import MemvidRetriever

logger = logging.getLogger(__name__)


class UnifiedLearningEngine:
    """Learn from all data sources using memvid archives"""
    
    def __init__(self, archive_dir: str = "/app/data/learning-archives"):
        self.archive_dir = Path(archive_dir)
    
    async def analyze_complete_history(self, user_id: str) -> Dict[str, Any]:
        """
        Analyze user's complete interaction history across all data types.
        
        Returns patterns from chats, journals, tasks, behaviors for holistic understanding.
        """
        if not self.archive_dir.exists():
            return {"error": "Archive directory not found", "patterns": {}}
        
        all_archives = list(self.archive_dir.glob("*.mp4"))
        
        if not all_archives:
            return {
                "message": "No archives yet - data will accumulate over time",
                "patterns": {},
                "note": "First archival runs quarterly after 90 days"
            }
        
        # Analyze each data type
        patterns = {
            "communication_style": await self._analyze_communication(user_id, all_archives),
            "emotional_patterns": await self._analyze_emotions(user_id, all_archives),
            "productivity_patterns": await self._analyze_productivity(user_id, all_archives),
            "behavioral_patterns": await self._analyze_behaviors(user_id, all_archives)
        }
        
        # Cross-correlate patterns
        patterns["correlations"] = await self._cross_correlate_all(user_id, all_archives)
        
        return {
            "user_id": user_id,
            "analyzed_at": datetime.now().isoformat(),
            "archives_analyzed": len(all_archives),
            "patterns": patterns
        }
    
    async def _analyze_communication(self, user_id: str, archives: List[Path]) -> Dict:
        """Learn communication preferences from all chat history"""
        chat_archives = [a for a in archives if 'chats-' in a.name]
        
        if not chat_archives:
            return {"note": "No chat archives yet"}
        
        all_chats = []
        for archive in chat_archives:
            index_file = archive.with_suffix('.idx')
            if not index_file.exists():
                continue
            
            try:
                retriever = MemvidRetriever(str(archive))
                # Get all chats for user
                user_chats = retriever.search(f"user_id", top_k=1000)
                
                for chat in user_chats:
                    try:
                        data = json.loads(chat['text'])
                        if data.get('user_id') == user_id:
                            all_chats.append(data)
                    except:
                        pass
            except Exception as e:
                logger.error(f"Error analyzing {archive}: {e}")
        
        if not all_chats:
            return {"note": "No user chats found in archives"}
        
        # Analyze patterns
        return {
            "total_chats_analyzed": len(all_chats),
            "avg_response_time": self._calculate_avg(all_chats, 'response_time'),
            "quality_trend": self._analyze_quality_trend(all_chats),
            "common_topics": self._extract_common_patterns(all_chats, 'user_message'),
            "preferred_models": self._count_field_values(all_chats, 'model_used')
        }
    
    async def _analyze_emotions(self, user_id: str, archives: List[Path]) -> Dict:
        """Analyze emotional patterns from journal archives"""
        journal_archives = [a for a in archives if 'journals-' in a.name]
        
        if not journal_archives:
            return {"note": "No journal archives yet"}
        
        all_journals = []
        for archive in journal_archives:
            try:
                retriever = MemvidRetriever(str(archive))
                journals = retriever.search(f"user_id", top_k=1000)
                
                for journal in journals:
                    try:
                        data = json.loads(journal['text'])
                        if data.get('user_id') == user_id:
                            all_journals.append(data)
                    except:
                        pass
            except:
                pass
        
        if not all_journals:
            return {"note": "No journal entries in archives"}
        
        return {
            "total_entries_analyzed": len(all_journals),
            "mood_distribution": self._count_field_values(all_journals, 'mood'),
            "avg_mood_score": self._calculate_avg(all_journals, 'mood_score'),
            "stress_indicators": self._find_negative_patterns(all_journals),
            "happiness_factors": self._find_positive_patterns(all_journals)
        }
    
    async def _analyze_productivity(self, user_id: str, archives: List[Path]) -> Dict:
        """Analyze productivity patterns from task archives"""
        task_archives = [a for a in archives if 'tasks-' in a.name]
        
        if not task_archives:
            return {"note": "No task archives yet"}
        
        all_tasks = []
        for archive in task_archives:
            try:
                retriever = MemvidRetriever(str(archive))
                tasks = retriever.search(f"user_id", top_k=1000)
                
                for task in tasks:
                    try:
                        data = json.loads(task['text'])
                        if data.get('user_id') == user_id:
                            all_tasks.append(data)
                    except:
                        pass
            except:
                pass
        
        if not all_tasks:
            return {"note": "No completed tasks in archives"}
        
        return {
            "total_tasks_analyzed": len(all_tasks),
            "avg_completion_time_hours": self._calculate_avg(all_tasks, 'time_to_complete_hours'),
            "completion_by_priority": self._count_field_values(all_tasks, 'priority'),
            "most_common_lists": self._count_field_values(all_tasks, 'list_name')
        }
    
    async def _analyze_behaviors(self, user_id: str, archives: List[Path]) -> Dict:
        """Analyze behavioral patterns from pattern archives"""
        pattern_archives = [a for a in archives if 'patterns-' in a.name]
        
        if not pattern_archives:
            return {"note": "No pattern archives yet"}
        
        all_patterns = []
        for archive in pattern_archives:
            try:
                retriever = MemvidRetriever(str(archive))
                patterns = retriever.search(f"user_id", top_k=1000)
                
                for pattern in patterns:
                    try:
                        data = json.loads(pattern['text'])
                        if data.get('user_id') == user_id:
                            all_patterns.append(data)
                    except:
                        pass
            except:
                pass
        
        if not all_patterns:
            return {"note": "No behavioral patterns in archives"}
        
        return {
            "total_patterns_analyzed": len(all_patterns),
            "pattern_types": self._count_field_values(all_patterns, 'pattern_type'),
            "high_confidence_patterns": [p for p in all_patterns if p.get('confidence', 0) > 0.8]
        }
    
    async def _cross_correlate_all(self, user_id: str, archives: List[Path]) -> Dict:
        """
        Discover patterns across ALL data types.
        
        Examples:
        - Mood in journals vs task completion
        - Social chats vs emotional wellbeing
        - Productivity vs time patterns
        """
        # This would require actual data to correlate
        # For now, return placeholder structure
        return {
            "note": "Cross-correlation available when sufficient data archived",
            "examples": [
                "Mood vs productivity correlation",
                "Social interaction vs happiness",
                "Task completion vs stress levels",
                "Time-of-day vs success rates"
            ]
        }
    
    # Helper methods
    def _calculate_avg(self, items: List[Dict], field: str) -> Optional[float]:
        """Calculate average of a numeric field"""
        values = [item.get(field) for item in items if isinstance(item.get(field), (int, float))]
        return round(sum(values) / len(values), 2) if values else None
    
    def _count_field_values(self, items: List[Dict], field: str) -> Dict:
        """Count occurrences of field values"""
        counts = {}
        for item in items:
            value = item.get(field)
            if value:
                counts[str(value)] = counts.get(str(value), 0) + 1
        return dict(sorted(counts.items(), key=lambda x: x[1], reverse=True)[:10])
    
    def _analyze_quality_trend(self, chats: List[Dict]) -> Dict:
        """Analyze quality scores over time"""
        scores = [c.get('quality_score') for c in chats if c.get('quality_score')]
        return {
            "avg_quality": round(sum(scores) / len(scores), 2) if scores else None,
            "total_rated": len(scores)
        }
    
    def _extract_common_patterns(self, items: List[Dict], field: str) -> List[str]:
        """Extract most common patterns from text field"""
        # Simplified - could use NLP for better extraction
        return ["Pattern extraction available when more data archived"]
    
    def _find_negative_patterns(self, journals: List[Dict]) -> List[str]:
        """Find stress/negative patterns in journals"""
        negative_moods = [j for j in journals if j.get('mood') in ['stressed', 'sad', 'anxious']]
        return [f"Found {len(negative_moods)} entries with negative mood indicators"]
    
    def _find_positive_patterns(self, journals: List[Dict]) -> List[str]:
        """Find happiness/positive patterns in journals"""
        positive_moods = [j for j in journals if j.get('mood') in ['happy', 'excited', 'content']]
        return [f"Found {len(positive_moods)} entries with positive mood indicators"]


# Global instance
unified_learner = UnifiedLearningEngine()




